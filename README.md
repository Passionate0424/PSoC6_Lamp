# 基于PSoC6的多模健康监测台灯系统

## 摘要

本文介绍了一款基于 PSoC6 的多模健康监测台灯系统，该系统融合多领域技术，实现了多元化的智能功能。

在台灯智能控制方面，具备自动开关节能设计，借助毫米波雷达的人体存在检测实现自动开关；支持伽马矫正自动调光，依据环境光强调整至合适亮度；还能通过舵机云台和视觉模块追踪功能，让台灯照射方向跟随书本移动，调整光照角度。

环境质量检测与评估上，可利用空气质量、温湿度等数据，通过轻量FCNN 神经网络进行环境质量评分，且能基于历史温湿度时间序列，借助轻量LSTM神经网络预测未来温湿度。

人体生理状态监测与评估方面，通过毫米波雷达模块的多普勒微位移感知，实现非接触式心率、呼吸率监测，并结合这些数据利用轻量FCNN神经网络预测人体压力状态。

工作状态监测等功能依靠视觉模块的YOLO视觉模型，识别手部动作以监测工作状态、玩手机状态、喝水动作，计算工作状态和专注度等数据，还能进行喝水计数与提醒。

同时，系统具备警戒监控功能，利用视觉模块的YOLO人体检测和视频 RTMP 推流，有人进入监控范围时会抓拍图片邮件发送给用户，并推送视频流供实时查看。

此外，该系统可通过语音模块与Deepseek进行语音对话，调用其评估环境状况并提供建议，用户还能利用云服务器部署的ThingsPanel物联网平台，通过电脑、手机APP远程查看检测数据和控制台灯开关。

该系统应用领域广泛，可作为智能家居系统的重要部分，也能用于儿童监护等场景，为用户带来便捷、智能的体验。

# 第一部分 作品概述

## 1.1功能与特性

### 1.1.1台灯智能控制

台灯支持自动开关节能设计。利用毫米波雷达的人体存在检测功能，当检测范围内有人体出现时，台灯自动开启，当人体离开检测区域时，台灯自动关闭。体现了环保节能设计。

支持伽马矫正自动调光，系统根据当前环境光强自动调整为合适亮度，使用伽马矫正更适合人眼感知特性。

支持角度自动调节。利用舵机云台和视觉模块的追踪功能，可以实现台灯照射方向跟随书本移动，调整合适光照角度。

### 1.1.2环境质量监测与评估

系统支持环境评分。利用采集的空气质量、温湿度等环境数据，通过部署的轻量FCNN神经网络进行环境质量评分便于用户做出调整。

系统支持温湿度预测。利用采集的历史温湿度时间序列，通过部署的轻量LSTM神经网络预测未来一段时间的温湿度数值，便于用户做出调整。

### 1.1.3人体生理状态监测与评估

系统支持非接触式心率、呼吸率监测。利用毫米波雷达模块的多普勒微位移感知功能，实现非接触的心率呼吸率监测。

支持人体压力状态监测。利用采集到的心率、呼吸率数据，利用部署的轻量FCNN神经网络，对人体压力状态进行预测。

### 1.1.4工作状态监测、喝水计数与提醒

利用视觉模块内部署的YOLO视觉模型，对人的手部动作进行识别监测，实现对工作状态、玩手机摸鱼状态、喝水动作的识别，据此计算人的工作状态和专注度等数据。便于用户调整工作状态和健康状况。

### 1.1.5警戒监控功能

利用视觉模块的YOLO人体检测功能、视频RTMP推流功能，当有人进入监控范围内，可识别并抓拍图片，利用邮件发送给用户，并将视频流推给用户便于实时查看。

### 1.1.6 AI大模型调用

利用语音模块实现了与Deepseek的语音对话，并可调用Deepseek对当前的环境状况进行评估，给用户提供调整建议。

### 1.1.7检测数据远程查看

利用云服务器部署的ThingsPanel物联网平台，用户可用电脑、手机APP远程查看台灯检测数据，远程控制台灯开关。

## 1.2应用领域

### 1.2.1智能家居

本智能台灯可以作为智能家居系统的重要一环，实现对用户工作状态、工作环境的评估，为用户提供建议，并可作为监控设备警戒书桌等重要的工作场所。

### 1.2.2儿童监护

本智能台灯能对用户的状态进行监控，并能远程实时查看视频，可以作为儿童监护设备使用，便于家长远程查看儿童状态。并可集成Deepseek、豆包等大模型助手，与儿童互动。

## 1.3主要技术特点

本作品融合多领域技术实现智能化场景应用，核心技术特点如下：

1. 多传感器融合技术：集成毫米波雷达、环境传感器（温湿度、空气质量）、视觉模块，实现人体存在检测、环境数据采集及动作识别，构建多维度感知体系。
2. 轻量化 AI 算法部署：采用轻量FCNN与LSTM神经网络，分别用于环境质量评分、人体压力状态监测及温湿度预测，在资源受限的嵌入式设备中实现高效推理。
3. 非接触式感知方案：利用毫米波雷达的多普勒效应，无需物理接触即可完成人体存在监测、心率及呼吸率检测，提升使用舒适性与卫生性。
4. 智能联动与自适应控制：通过视觉识别与舵机云台实现台灯角度自动调节，结合伽马矫正算法实现环境光自适应调光，优化用户体验。
5. 跨平台数据交互：基于 ThingsPanel 物联网平台与RTMP推流技术，支持远程监控及多终端（手机、电脑）实时访问，实现设备智能化管理
6. 警戒监控功能：依托视觉模块搭载的 YOLOv8 人体检测功能与视频 RTMP 推流功能，可快速完成人体识别并抓拍现场图片，通过邮件将图片发送至用户；同时实时将视频流推送至用户端。
7. 工作状态数据分析：基于YOLOv5视觉模型的工作状态监测所收集的专注工作时长、摸鱼时长占比等数据，系统会基于算法生成工作评分，专注度和能量值评估，为用户提供针对性的语音建议。
8. 语音交互与环境评估：通过语音模块与Deepseek实现语音对话。用户经 SG2002 输入语音问题，传输至 PSoC6 调用Deepseek模型，完成环境评估并生成调整建议后，传回 SG2002 转语音播放，提供便捷指导。

## 1.4主要性能指标

| 毫米波雷达检测距离       | 0.5-1.2 米，检测角度 ±60° |
| ------------------------ | ------------------------- |
| 环境光调光范围           | 10-1800lux                |
| 台灯灯头角度调节范围     | 水平 180°，垂直 0-60°     |
| 环境评分FCNN模型推理时间 | 891微秒                   |
| 压力预测FCNN模型推理时间 | 336微秒                   |
| 温湿度预测LSTM模型推理时间 | 1776微秒                  |

## 1.5主要创新点

1. 多模态非接触感知融合：创新性结合毫米波雷达的多普勒微位移检测技术，实现人体存在、心率及呼吸率的非接触式监测，突破传统接触式传感的使用局限。
2. 轻量化 AI 算法异构部署：在嵌入式设备中集成轻量级FCNN与LSTM神经网络，同步实现环境质量评分、人体压力状态评估及温湿度时序预测，兼顾计算效率与资源消耗。
3. 视觉-机械协同自适应控制：通过YOLO 视觉模型与舵机云台的联动，构建 “视觉识别-运动控制” 闭环系统，实现台灯照射角度跟随书本移动的动态调节功能。
4. 跨领域技术场景化集成：融合RT-Thread LLM 软件包调用Deepseek 大模型，结合物联网平台远程监控与 RTMP 推流警戒功能，形成“环境监测-状态评估-智能建议-远程管控”的完整生态链。
5. 沉浸式智能交互生态：打通“语音输入-音频处理-AI 模型回答-语音合成播报” 全流程，形成从感知、分析到交互反馈的完整闭环，强化人机协同体验，让设备响应更智能。
6. 多模式智能联动控制：基于PSoC6控制，集成警戒、工作监测、灯光追寻、推流、语音输入等多模式，实现场景化智能切换，覆盖安全防护、行为分析、交互控制等多元需求，打破单一功能局限。

# 第二部分 系统组成及功能说明

## 2.1整体介绍

台灯主控采用英飞凌PSoC6，搭载RT-Thread操作系统，用于驱动多种传感器外设、运行LSTM、FCNN神经网络算法、调用Deepseek语言大模型、使用LVGL用户交互界面，实现环境评估、工作评估等核心功能。同时使用算能SG2002提供算力支持，搭载Maixpy提供的Linux环境进行开发，部署基于YOLOv5和YOLOv8-pose的视觉神经网络，实现对人员工作状态的分析监测。同时利用物联网技术和流媒体技术，实现台灯的远程控制与监控警戒功能的远程查看。

### 2.1.1 硬件驱动

本系统以PSoC6作为主控芯片，通过I2C总线连接ENS160空气质量传感器、BMP280气压温度传感器、BH1750光强传感器、SHT31温湿度传感器，实现对环境数据的实时采集；通过串口与SG2002与毫米波雷达模块进行通信；利用PWM波控制LED的亮度调节与舵机云台的转向，其中LED调光由PWM调光专用模块转换为电压输出实现，舵机云台则驱动摄像头与LED灯共同转动，实现视角控制与目标追踪；显示屏通过硬件SPI接口驱动并结合LVGL图形库进行界面设计，触摸功能由I2C连接的GT911触控IC实现，构建了一个集成感知、显示、控制于一体的嵌入式台灯系统。

### 2.1.2 环境信息采集与评分

环境信息由 PSoC6 主控通过 I2C 接口定时采集，涵盖温度（temp）、湿度（humi）、光照强度（lux）、二氧化碳浓度（eCO₂）、总挥发性物质浓度（TVOC）等关键指标。部署的两个轻量LSTM神经网络将根据温湿度时间序列计算未来一段时间的温湿度预测值；同时使用训练的FCNN神经网络对环境舒适度进行分类，并采用加权区间评分机制，将环境舒适度转换为直观的分数显示，供用户了解和调整。

### 2.1.3 人体生理信息采集与评估

PSoC6通过串口驱动R60ABD1毫米波雷达模块，读取当前区域人体存在状态、人体心率、呼吸率。利用人体存在状态，台灯可实现用户进入区域自动开启，离开区域自动关闭，提高台灯的便利性与节能性。利用非接触式采集的心率、呼吸数据，输入训练的FCNN神经网络，实现对人体压力状态的评估。

### 2.1.4 工作状态检测与评分

SG2002通过GC4653摄像头采集桌面图像，其中一个YOLOv5模型负责通过采集到的图像准确的识别手部位置，而另外一个YOLOv5S模型则负责识别桌面物品和各自的位置，通过计算手识别框与物品识别框的重合程度，分析用户当前的动作，并输出为工作、游戏、休息时间，将这些识别结果整理后打包发送给PSoC6，PSoC6则结合这些信息由工作状态检测算法来统计分析当前使用者的工作状态评分、精力值与专注度。同时用户可自行设定工作时间、休息时间、喝水提醒间隔，系统将按时提醒用户工作、休息、喝水。

### 2.1.5 台灯视角自动控制

用户可自行选择追踪模式的开启与关闭，追踪对象可选择为手部和书本。当处于追踪手部模式时，PID算法驱动舵机云台追踪用户的手部，可加强动作识别与工作状态检测的连续性，并为手部提供充足照明。同时考虑到看书学习这一高频使用场景，系统提供了书本追踪模式，台灯可根据书本位置调整光照角度，为学习提供合适照明。

### 2.1.6 警戒监控模式

考虑到用户希望在离开时对自己的工作环境进行有效监控、防止外人乱动自己物品这一需求，我们设计了警戒监控模式。SG2002此时将持续使用YOLOv8-pose模型检测人体和各个关键点的位置，并经过姿态检测算法得到人体目前的姿态信息，如果识别到有人出现在画面中则会通知PSoC6，PSoC6使用SMTP协议发送邮件通知使用者，同时用户可以打开RTMP推流开关，实时观看当前监控画面。

### 2.1.7 云平台

##### 2.1.7.1 ThingsPanel物联网平台

我们将开源的ThingsPanel物联网平台部署在我们的腾讯云Linux服务器中，PSoC6使用MQTT协议将数据上传给物联网平台，并接收物联网平台下发的指令。实现数据的远程查看与台灯的远程控制。

图2.1.7-1：ThingsPanel物联网平台网页端界面

##### 2.1.7.2 SRS流媒体平台

我们将开源的SRS流媒体平台部署在我们的腾讯云Linux服务器中，台灯系统使用RTMP协议将视频流推流至服务器，便于用户实时查看。
图2.1.7-3：SRS流媒体平台界面

### 2.1.8 语言大模型

用户点击“按住说话”按钮后，SG2002开始用板载麦克风录音，说话完成后，松开按钮录音结束，随后将这段录音提交到百度智能云平台进行语音识别，再将文字信息通过串口传输给PSoC6，调用Deepseek大模型，等待模型生成文字后，再将文字传给SG2002合成语音，最后经过音频功放由外接扬声器播放出来，实现一次对话。

同时，为了用户更方便地获取环境调整建议，我们设置了“环境建议”按钮，用户可一键将当前环境状态信息上传给Deepseek并获取调整建议。

## 2.2硬件系统介绍

### 2.2.1 硬件整体介绍：

硬件部分，我们使用了英飞凌PSoC6作为主控，搭载核心算法，使用SG2002提供算力支持。使用ST7789显示芯片与GT911触控IC驱动的3.2寸触摸屏与用户交互。无线WIFI模块使用RW007。传感器包括ENS160空气质量传感器、BMP280气压温度传感器、BH1750光强传感器、SHT31温湿度传感器、R60ABD1毫米波雷达模块。其中ENS160空气质量传感器、BMP280气压温度传感器、BH1750光强传感器、SHT31温湿度传感器位于RTduino拓展版上。其他硬件模块包括悬挂SG90舵机云台、PWM调光模块、扬声器、电源模块。

### 2.2.2 机械设计介绍；

台灯底座设计了较大空间用于放置开发板、电源模块等硬件模块，表面开孔用于安装屏幕。顶部延长支架用于安装舵机云台。支撑杆采用两节分段设计，便于打印和组装。整体CAD截图如下所示：

图2.2.2-1：台灯外壳整体CAD设计图

台灯灯头安装于舵机云台上。设计凹槽用于安装LED灯板和视觉模块。灯罩盖板采用可拆卸设计，可以适应不同光强要求，便于更换合适灯罩。灯头也设计了连接件，用于固定灯罩与盖板。CAD设计图如下所示：

图2.2.2-2 灯头结构图

### 2.2.3 电路各模块介绍

该部分传感器拓展板为自行设计，其余硬件模块均为购买。

##### 2.2.3.1 PSoC6评估板与RTduino传感器拓展板

该部分作为系统的核心控制。

![img](tmp/112568559618_docx.datword_media_image10.jpeg)

图2.2.3-1：PSoC6评估板与RTduino传感器拓展板

##### 2.2.3.2 电源模块

使用DC9V输入，获得稳定的5V、3.3V电源供应。

图2.2.3-2：电源模块

##### 2.2.3.3 PWM调光模块

该模块将输入的PWM波转为对应大小的电压值，用来调整LED亮度。

图2.2.3-3：PWM调光模块

##### 2.2.3.4 I2C传感器拓展板

该部分用于连接BH1750光强传感器和ENS160空气质量传感器，外置测量光强和空气质量。
图2.2.3-4：I2C传感器拓展板

##### 2.2.3.5 R60ABD1毫米波雷达

该模块用于检测人体存在状态、心率、呼吸率。

图2.2.3-5：毫米波雷达模块

##### 2.2.3.6 SG2002开发板

SG2002作为YOLO视觉模型的算力支持和语音模块，使用Maixpy提供的Linux环境开发。配备GC4653摄像头进行视觉识别。

图2.2.3-6：SG2002开发板

##### 2.2.3.7 拓展板

该部分拼插于RTduino拓展板之上，用于稳定PSoC6开发板与各模块之间的连接。

图2.2.3-7：拓展板

## 2.3软件系统介绍

### 2.3.1软件整体介绍；

##### 2.3.1.1 英飞凌PSoC6部分

PSoC6上的软件程序主要包括以下几个模块： 传感器驱动模块、舵机控制模块、LED控制模块、云端LLM AI对话模块、本地部署轻量化AI模块、工作状态检测与评估模块、屏幕图形操作界面模块。

##### 2.3.1.2 SG2002部分

SG2002上的软件程序主要包括以下几个模块：手部识别模块、桌面物品识别模块、人体检测识别模块、通信模块。以上模块之间没有联系，必须与PSoC6配合才能工作。

### 2.3.2软件各模块介绍

##### 2.3.2.1 PSoC6部分

###### （1）硬件、传感器驱动

该部分BMP280气压温度传感器、BH1750光强传感器、SHT31温湿度传感器、GT911触摸IC、SG90舵机均使用RT-Thread提供的软件包驱动，ENS160空气质量传感器通过RTduino兼容层，移植官方驱动库进行驱动。ST7789V显示芯片由于RT-Thread现有软件包功能较少且未适配SPI驱动，故自行适配了驱动，后期会整理上传为软件包。R60ABD1雷达串口驱动模块也为自行适配，后期整理上传软件包。

###### （2）轻量化神经网络模块

本模块的控制流程图如下图所示：

图2.3.2-1：神经网络模块流程图

使用TensorFlow框架进行搭建与训练。使用RT-Thread的nnom库软件包进行int8量化部署。所使用的模型结构如下图所示：

图2.3.2-2：模型结构图，左一环境舒适度分类模型，中间压力预测模型，右一温湿度预测模型

部署后使用nnom库提供的性能测试函数进行推理测试得到，环境评分FCNN模型推理时间约891微秒，压力预测FCNN模型推理时间约312微秒，温湿度预测LSTM模型推理时间约1776微秒，测试结果如下图所示。

图2.3.2-3：环境评分FCNN模型推理测试结果


图2.3.2-4：压力预测FCNN模型推理测试结果

图2.3.2-5：温湿度LSTM模型推理测试结果

###### （3）LED控制模块

本模块的控制流程图如下图所示：

图2.3.2-6：LED控制算法流程图

LED 控制模块具备自动与手动两种调控模式，为照明提供灵活且智能的解决方案。手动模式下，模块根据屏幕亮度调节滑动条的数值，转化为对应占空比的 PWM 波以改变 LED 亮度，满足用户个性化需求；自动模式则基于BH1750光传感器采集的外界亮度信息，结合伽马调节函数输出 PWM 波实现自动调光，该函数突破简单的反比互补关系，适合人眼的非线性感知，兼顾环境适配与健康保护。同时使用一阶滤波使亮度改变平滑，防止跳变。

同时，伽马调光前，亮度自动调节会按照下图所示曲线计算亮度系数，使得在外界

较暗时适当调小亮度以达到护眼效果。

图2.3.2-7：LED控制算法流程图

###### （4）工作状态监测与评估模块

图2.3.2-8：工作状态监测算法整体流程图

模块整体流程图如上图所示，这个模块为“工作监测模式”核心模块。启动“工作监测模式”后，不断接收来自SG2002的工作状态判断结果，作为输入。通过统计工作、使用手机、静息状态（除之前两者之外状态）的持续时间，对当前精力值、工作专注度、工作状态进行评估，同时根据用户设置的工作定时、休息定时、喝水提醒定时，按时对用户进行语音提醒。

工作状态评分函数以工作及玩手机状态统计时间为输入，如果当前时间处于用户设置的工作时间段，获取玩手机时间增长值，触发每分钟扣十分的负向评分。同时若当前精力值过低时，也会根据工作持续时间进行扣分，提醒用户不要过分疲劳工作。流程图如下所示


图2.3.2-9：工作状态评分算法流程图

精力值计算函数依据工作、玩手机摸鱼、静息三种状态，分别获取对应时间增长值；同时，系数计算函数会根据当前环境评分与压力状态，测算精力值计算系数，实现当前环境舒适度越差、人体压力越高，工作导致的精力值下降越快，玩手机和静息状态导致的精力值恢复越慢。流程图如下所示

图2.3.2-10：精力值计算算法流程图

工作专注度评分函数以工作及玩手机状态统计时间为输入，如果当前时间处于用户设置的工作时间段，获取玩手机时间的占比，玩手机时间占比越高，专注度计算结果越低。流程图如下所示

图2.3.2-11：专注度计算算法流程图

喝水提醒模块用定时器进行构建。根据用户设置的喝水提醒时间间隔，设置定时器，回调函数内触发语音提醒；同时，当用户喝水状态发生时执行重置定时器操作，让喝水提醒定时器重新启动计时，以此动态地循环提醒用户喝水，助力用户养成规律饮水习惯。流程图如下所示。

图2.3.2-12：喝水提醒算法流程图

###### （5） 邮件发送模块

警戒监控模式开启，当摄像头或毫米波雷达监测到有人体出现时，系统会使用SMTP协议向用户发送邮件进行提醒，用户可点击邮件中的链接查看实时监控。

图2.3.2-13：邮件发送模块流程图

###### （6） 舵机控制模块

该模块读取SG2002上报的目标坐标，经卡尔曼滤波后，计算相对于屏幕中心的误差值，输入PID控制线程对SG90舵机进行控制，实现对手部或书本的追踪。

图2.3.2-14：舵机控制模块流程图

###### （7）屏幕图形操作界面模块

该部分使用LVGL图形库进行界面渲染设计，使用GUI Guider软件辅助设计。用于用户近场控制。

##### 2.3.2.2 SG2002部分

SG2002主要用于部署YOLO视觉模型，受PSoC6串口发送的指令控制，该部分的算法较为简单，在此仅简单展示。


图2.3.2-15：SG2002模块整体框架图

###### （1） 手部识别模块

在智能台灯交互系统里，我们把 YOLOv5S 手部识别模型部署在 SG2002 上。手部识别模块同时与物品识别模块一起作用，通过计算手部与物品的重叠面积来判断是否使用进而判断其工作状态。追踪模式下，模型识别出手部后，会计算识别结果坐标，再通过串口传递给 PSoC6。PSoC6 收到数据，依靠舵机控制模块，就能驱动摄像头精准追踪手部 。在手部识别数据集筛选时，我们将那些边界框过大或过小的样本剔除，以得到更符合实际识别场景的手部识别数据集。

###### （2） 桌面物品识别模块

桌面物品识别模块使用了部署在SG2002的YOLOv5桌面物品识别模型。可以识别包括电脑键盘，手机，鼠标，书本，咖啡杯，钢笔的六种物品。结合桌面学习场景的识别需求，重点加强了书本和钢笔识别，我们进行了数据集的增添与修改适当增加了书本的权重，有效改善了这一点。模型与追踪模式和工作监测模式相配合。模块会配合手部识别模块根据物品外框与手重叠比例，判断人是否使用物品进而判断其工作状态实行监测；以及输出书本的中心坐标通过串口传输给PSoC6与舵机云台联动实现光照的追踪。

###### （3） 人体检测与姿态识别模块

该模块在SG2002上部署了YOLOv8-pose人体关键点模型，得到人体的关键点信息，在警戒模式下，如果检测到人体信息，则会发送有人信号通过串口传输给PSoC6。通过RTMP协议，将监控画面推流到自行部署的SRS服务器中，可在多台终端设备上观看直播画面。

# 第三部分 完成情况及性能参数

## 3.1 整体介绍

PSoC6开发板和RTduino拓展板置于台灯底座空间中，摄像头与LED灯板共同安装在灯头组件上。灯头通过舵机云台悬挂在台灯支架下方。整体外壳均使用3D打印制作。

## 3.2 工程成果

### 3.2.1 机械成果

整个系统的正面侧面背面如下图所示：

图3.2.1-1：台灯整体正面

图3.2.1-2：台灯整体侧面

图3.2.1-3：台灯整体背面

### 3.2.2 软件成果

图3.2.2-1 LVGL界面效果（传感器数据暂时用---替代）

## 3.2.3 特性成果:

该部分文字说明难以有效展示，请查看演示视频
